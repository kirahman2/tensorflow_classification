{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation\n",
    "from keras.layers.core import Dense, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import categorical_crossentropy\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import *\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_files = '/Users/krahman/work/tutorials/tensorflow_classification/data/'\n",
    "\n",
    "train_samples = pd.read_csv(filepath_files + 'mod_x_train.csv').drop('Unnamed: 0', axis=1)\n",
    "train_labels = pd.read_csv(filepath_files + 'mod_y_train.csv').drop('Unnamed: 0', axis=1)\n",
    "test_samples = pd.read_csv(filepath_files + 'mod_x_test.csv').drop('Unnamed: 0', axis=1)\n",
    "test_labels = pd.read_csv(filepath_files + 'mod_y_test.csv').drop('470624', axis=1)\n",
    "test_labels = test_labels.rename(columns={\"0\":\"isFraud\"})\n",
    "\n",
    "test_samples = pd.concat([test_samples, test_labels], axis=1)\n",
    "test_samples, val_samples = train_test_split(test_samples, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = train_labels\n",
    "test_labels = test_samples.pop('isFraud')\n",
    "val_labels = val_samples.pop('isFraud')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = np.array(train_labels)\n",
    "test_labels = np.array(test_labels.fillna(0).astype(int))\n",
    "val_labels = np.array(val_labels)\n",
    "\n",
    "train_samples = np.array(train_samples)\n",
    "test_samples = np.array(test_samples)\n",
    "val_samples = np.array(val_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaled_train_samples = scaler.fit_transform(train_samples)#.reshape(-1,1))\n",
    "scaled_test_samples = scaler.fit_transform(test_samples)#.reshape(-1,1))\n",
    "scaled_val_samples = scaler.fit_transform(val_samples)#.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(4096, input_shape=(233,), activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "model.compile(Adam(lr=.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(scaled_train_samples, train_labels, validation_data=(scaled_val_samples, val_labels), \n",
    "          batch_size=10, epochs=10, shuffle=True, verbose=2, workers=8, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing .00001 \n",
    "# best 4096, 64, batch=10 lr=.0001\n",
    "model2 = Sequential([\n",
    "    Dense(4096, input_shape=(233,), activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "model2.compile(Adam(lr=.00001), loss=losses.sparse_categorical_crossentropy, metrics=['accuracy'])\n",
    "model2.fit(scaled_train_samples, train_labels, validation_data=(scaled_val_samples, val_labels), \n",
    "          batch_size=10, epochs=15, shuffle=True, verbose=2, workers=8, use_multiprocessing=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing .0001 \n",
    "# best 4096, 64, batch=10 lr=.0001\n",
    "model2 = Sequential([\n",
    "    Dense(4096, input_shape=(233,), activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "model2.compile(Adam(lr=.0001), loss=losses.sparse_categorical_crossentropy, metrics=['accuracy'])\n",
    "model2.fit(scaled_train_samples, train_labels, validation_data=(scaled_val_samples, val_labels), \n",
    "          batch_size=10, epochs=15, shuffle=True, verbose=2, workers=8, use_multiprocessing=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 190000 samples, validate on 11811 samples\n",
      "Epoch 1/15\n",
      " - 321s - loss: 0.3992 - accuracy: 0.8250 - val_loss: 0.6065 - val_accuracy: 0.7405\n",
      "Epoch 2/15\n",
      " - 321s - loss: 0.2876 - accuracy: 0.8835 - val_loss: 0.6200 - val_accuracy: 0.7806\n",
      "Epoch 3/15\n",
      " - 321s - loss: 0.2524 - accuracy: 0.8997 - val_loss: 0.5328 - val_accuracy: 0.8472\n",
      "Epoch 4/15\n",
      " - 321s - loss: 0.2338 - accuracy: 0.9080 - val_loss: 0.5947 - val_accuracy: 0.8381\n",
      "Epoch 5/15\n",
      " - 323s - loss: 0.2218 - accuracy: 0.9127 - val_loss: 0.5674 - val_accuracy: 0.8559\n",
      "Epoch 6/15\n",
      " - 320s - loss: 0.2130 - accuracy: 0.9163 - val_loss: 0.5867 - val_accuracy: 0.8567\n",
      "Epoch 7/15\n",
      " - 321s - loss: 0.2056 - accuracy: 0.9193 - val_loss: 0.5353 - val_accuracy: 0.8733\n",
      "Epoch 8/15\n",
      " - 322s - loss: 0.1995 - accuracy: 0.9226 - val_loss: 0.5687 - val_accuracy: 0.8657\n",
      "Epoch 9/15\n",
      " - 321s - loss: 0.1941 - accuracy: 0.9243 - val_loss: 0.5238 - val_accuracy: 0.8829\n",
      "Epoch 10/15\n",
      " - 321s - loss: 0.1890 - accuracy: 0.9275 - val_loss: 0.5222 - val_accuracy: 0.8850\n",
      "Epoch 11/15\n",
      " - 321s - loss: 0.1847 - accuracy: 0.9292 - val_loss: 0.5567 - val_accuracy: 0.8758\n",
      "Epoch 12/15\n",
      " - 320s - loss: 0.1809 - accuracy: 0.9307 - val_loss: 0.5255 - val_accuracy: 0.8917\n",
      "Epoch 13/15\n",
      " - 320s - loss: 0.1769 - accuracy: 0.9324 - val_loss: 0.5034 - val_accuracy: 0.8982\n",
      "Epoch 14/15\n",
      " - 320s - loss: 0.1731 - accuracy: 0.9337 - val_loss: 0.5391 - val_accuracy: 0.8800\n",
      "Epoch 15/15\n",
      " - 320s - loss: 0.1701 - accuracy: 0.9353 - val_loss: 0.4987 - val_accuracy: 0.8969\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1aedf472d0>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing lr=.00001\n",
    "model3 = Sequential([\n",
    "    Dense(4096, input_shape=(233,), activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "model3.compile(Adam(lr=.00001), loss=losses.sparse_categorical_crossentropy, metrics=['accuracy'])\n",
    "model3.fit(scaled_train_samples, train_labels, validation_data=(scaled_val_samples, val_labels), \n",
    "          batch_size=10, epochs=15, shuffle=True, verbose=2, workers=8, use_multiprocessing=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 190000 samples, validate on 11811 samples\n",
      "Epoch 1/15\n",
      " - 317s - loss: 0.3013 - accuracy: 0.8706 - val_loss: 0.5817 - val_accuracy: 0.8201\n",
      "Epoch 2/15\n",
      " - 320s - loss: 0.2361 - accuracy: 0.9040 - val_loss: 0.8494 - val_accuracy: 0.7330\n",
      "Epoch 3/15\n",
      " - 321s - loss: 0.2172 - accuracy: 0.9126 - val_loss: 0.5897 - val_accuracy: 0.8395\n",
      "Epoch 4/15\n",
      " - 322s - loss: 0.2035 - accuracy: 0.9185 - val_loss: 0.6941 - val_accuracy: 0.7921\n",
      "Epoch 5/15\n",
      " - 323s - loss: 0.1939 - accuracy: 0.9234 - val_loss: 0.8733 - val_accuracy: 0.7179\n",
      "Epoch 6/15\n",
      " - 323s - loss: 0.1863 - accuracy: 0.9267 - val_loss: 0.7315 - val_accuracy: 0.7997\n",
      "Epoch 7/15\n",
      " - 322s - loss: 0.1801 - accuracy: 0.9291 - val_loss: 0.6606 - val_accuracy: 0.8119\n",
      "Epoch 8/15\n",
      " - 323s - loss: 0.1746 - accuracy: 0.9321 - val_loss: 0.5967 - val_accuracy: 0.8418\n",
      "Epoch 9/15\n",
      " - 322s - loss: 0.1687 - accuracy: 0.9346 - val_loss: 0.5432 - val_accuracy: 0.8443\n",
      "Epoch 10/15\n",
      " - 325s - loss: 0.1653 - accuracy: 0.9354 - val_loss: 0.6724 - val_accuracy: 0.7857\n",
      "Epoch 11/15\n",
      " - 325s - loss: 0.1614 - accuracy: 0.9373 - val_loss: 0.6908 - val_accuracy: 0.8141\n",
      "Epoch 12/15\n",
      " - 326s - loss: 0.1574 - accuracy: 0.9394 - val_loss: 0.7585 - val_accuracy: 0.8104\n",
      "Epoch 13/15\n",
      " - 326s - loss: 0.1541 - accuracy: 0.9410 - val_loss: 0.6981 - val_accuracy: 0.8379\n",
      "Epoch 14/15\n",
      " - 326s - loss: 0.1508 - accuracy: 0.9421 - val_loss: 1.0155 - val_accuracy: 0.7488\n",
      "Epoch 15/15\n",
      " - 328s - loss: 0.1484 - accuracy: 0.9433 - val_loss: 0.6064 - val_accuracy: 0.8364\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1ae3867fd0>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing epochs=15 \n",
    "model3 = Sequential([\n",
    "    Dense(4096, input_shape=(233,), activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "model3.compile(Adam(lr=.0001), loss=losses.sparse_categorical_crossentropy, metrics=['accuracy'])\n",
    "model3.fit(scaled_train_samples, train_labels, validation_data=(scaled_val_samples, val_labels), \n",
    "          batch_size=10, epochs=15, shuffle=True, verbose=2, workers=8, use_multiprocessing=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 190000 samples, validate on 11811 samples\n",
      "Epoch 1/15\n",
      " - 165s - loss: 0.4128 - accuracy: 0.8135 - val_loss: 0.3503 - val_accuracy: 0.8836\n",
      "Epoch 2/15\n",
      " - 145s - loss: 0.3033 - accuracy: 0.8710 - val_loss: 0.4259 - val_accuracy: 0.8683\n",
      "Epoch 3/15\n",
      " - 135s - loss: 0.2738 - accuracy: 0.8867 - val_loss: 0.4524 - val_accuracy: 0.8655\n",
      "Epoch 4/15\n",
      " - 136s - loss: 0.2579 - accuracy: 0.8946 - val_loss: 0.4884 - val_accuracy: 0.8678\n",
      "Epoch 5/15\n",
      " - 139s - loss: 0.2475 - accuracy: 0.8993 - val_loss: 0.4599 - val_accuracy: 0.8782\n",
      "Epoch 6/15\n",
      " - 143s - loss: 0.2395 - accuracy: 0.9038 - val_loss: 0.5160 - val_accuracy: 0.8651\n",
      "Epoch 7/15\n"
     ]
    }
   ],
   "source": [
    "# testing .00001\n",
    "model3 = Sequential([\n",
    "    Dense(128, input_shape=(233,), activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "model3.compile(Adam(lr=.00001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model3.fit(scaled_train_samples, train_labels, validation_data=(scaled_val_samples, val_labels), \n",
    "          batch_size=10, epochs=15, shuffle=True, verbose=2, workers=8, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing\n",
    "model3 = Sequential([\n",
    "    Dense(128, input_shape=(233,), activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "model3.compile(Adam(lr=.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model3.fit(scaled_train_samples, train_labels, validation_data=(scaled_val_samples, val_labels), \n",
    "          batch_size=10, epochs=15, shuffle=True, verbose=2, workers=8, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing .00001\n",
    "model3 = Sequential([\n",
    "    Dense(512, input_shape=(233,), activation='relu'),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "model3.compile(Adam(lr=.00001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model3.fit(scaled_train_samples, train_labels, validation_data=(scaled_val_samples, val_labels), \n",
    "          batch_size=10, epochs=15, shuffle=True, verbose=2, workers=8, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing .0001\n",
    "model3 = Sequential([\n",
    "    Dense(512, input_shape=(233,), activation='relu'),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "model3.compile(Adam(lr=.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model3.fit(scaled_train_samples, train_labels, validation_data=(scaled_val_samples, val_labels), \n",
    "          batch_size=10, epochs=15, shuffle=True, verbose=2, workers=8, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 190000 samples, validate on 11811 samples\n",
      "Epoch 1/15\n",
      " - 217s - loss: 0.3056 - accuracy: 0.8685 - val_loss: 0.3789 - val_accuracy: 0.9004\n",
      "Epoch 2/15\n",
      " - 215s - loss: 0.2416 - accuracy: 0.9009 - val_loss: 0.4035 - val_accuracy: 0.8996\n",
      "Epoch 3/15\n",
      " - 215s - loss: 0.2200 - accuracy: 0.9112 - val_loss: 0.4145 - val_accuracy: 0.8894\n",
      "Epoch 4/15\n",
      " - 215s - loss: 0.2051 - accuracy: 0.9178 - val_loss: 0.4427 - val_accuracy: 0.8854\n",
      "Epoch 5/15\n",
      " - 235s - loss: 0.1941 - accuracy: 0.9224 - val_loss: 0.4560 - val_accuracy: 0.8824\n",
      "Epoch 6/15\n",
      " - 215s - loss: 0.1839 - accuracy: 0.9267 - val_loss: 0.5035 - val_accuracy: 0.8733\n",
      "Epoch 7/15\n",
      " - 215s - loss: 0.1762 - accuracy: 0.9307 - val_loss: 0.5650 - val_accuracy: 0.8870\n",
      "Epoch 8/15\n",
      " - 216s - loss: 0.1690 - accuracy: 0.9343 - val_loss: 0.7868 - val_accuracy: 0.8779\n",
      "Epoch 9/15\n",
      " - 215s - loss: 0.1631 - accuracy: 0.9365 - val_loss: 0.7460 - val_accuracy: 0.8504\n",
      "Epoch 10/15\n",
      " - 216s - loss: 0.1577 - accuracy: 0.9385 - val_loss: 0.8295 - val_accuracy: 0.8385\n",
      "Epoch 11/15\n",
      " - 216s - loss: 0.1531 - accuracy: 0.9410 - val_loss: 0.8204 - val_accuracy: 0.8689\n",
      "Epoch 12/15\n",
      " - 215s - loss: 0.1485 - accuracy: 0.9429 - val_loss: 0.8675 - val_accuracy: 0.8364\n",
      "Epoch 13/15\n",
      " - 214s - loss: 0.1441 - accuracy: 0.9442 - val_loss: 0.8762 - val_accuracy: 0.8562\n",
      "Epoch 14/15\n",
      " - 214s - loss: 0.1400 - accuracy: 0.9459 - val_loss: 1.0218 - val_accuracy: 0.8612\n",
      "Epoch 15/15\n",
      " - 216s - loss: 0.1363 - accuracy: 0.9473 - val_loss: 0.9056 - val_accuracy: 0.8253\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1af7bfe310>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing\n",
    "model3 = Sequential([\n",
    "    Dense(256, input_shape=(233,), activation='relu'),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "model3.compile(Adam(lr=.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model3.fit(scaled_train_samples, train_labels, validation_data=(scaled_val_samples, val_labels), \n",
    "          batch_size=10, epochs=15, shuffle=True, verbose=2, workers=8, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing .00001\n",
    "model3 = Sequential([\n",
    "    Dense(256, input_shape=(233,), activation='relu'),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "model3.compile(Adam(lr=.00001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model3.fit(scaled_train_samples, train_labels, validation_data=(scaled_val_samples, val_labels), \n",
    "          batch_size=10, epochs=15, shuffle=True, verbose=2, workers=8, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 190000 samples, validate on 11811 samples\n",
      "Epoch 1/15\n",
      " - 153s - loss: 0.3042 - accuracy: 0.8687 - val_loss: 0.4330 - val_accuracy: 0.8751\n",
      "Epoch 2/15\n",
      " - 151s - loss: 0.2425 - accuracy: 0.9009 - val_loss: 0.4721 - val_accuracy: 0.8524\n",
      "Epoch 3/15\n",
      " - 151s - loss: 0.2201 - accuracy: 0.9107 - val_loss: 0.4384 - val_accuracy: 0.8772\n",
      "Epoch 4/15\n",
      " - 150s - loss: 0.2046 - accuracy: 0.9182 - val_loss: 0.4329 - val_accuracy: 0.8684\n",
      "Epoch 5/15\n",
      " - 151s - loss: 0.1935 - accuracy: 0.9229 - val_loss: 0.5213 - val_accuracy: 0.8418\n",
      "Epoch 6/15\n",
      " - 150s - loss: 0.1842 - accuracy: 0.9269 - val_loss: 0.3829 - val_accuracy: 0.9070\n",
      "Epoch 7/15\n",
      " - 150s - loss: 0.1754 - accuracy: 0.9309 - val_loss: 0.6673 - val_accuracy: 0.8062\n",
      "Epoch 8/15\n",
      " - 150s - loss: 0.1681 - accuracy: 0.9342 - val_loss: 0.5271 - val_accuracy: 0.8724\n",
      "Epoch 9/15\n",
      " - 152s - loss: 0.1615 - accuracy: 0.9371 - val_loss: 0.5224 - val_accuracy: 0.8867\n",
      "Epoch 10/15\n",
      " - 151s - loss: 0.1570 - accuracy: 0.9393 - val_loss: 0.7257 - val_accuracy: 0.8350\n",
      "Epoch 11/15\n",
      " - 151s - loss: 0.1516 - accuracy: 0.9415 - val_loss: 0.6988 - val_accuracy: 0.8805\n",
      "Epoch 12/15\n",
      " - 153s - loss: 0.1471 - accuracy: 0.9429 - val_loss: 0.7589 - val_accuracy: 0.8705\n",
      "Epoch 13/15\n",
      " - 151s - loss: 0.1426 - accuracy: 0.9450 - val_loss: 0.6859 - val_accuracy: 0.8587\n",
      "Epoch 14/15\n",
      " - 150s - loss: 0.1386 - accuracy: 0.9468 - val_loss: 0.8228 - val_accuracy: 0.8378\n",
      "Epoch 15/15\n",
      " - 150s - loss: 0.1346 - accuracy: 0.9485 - val_loss: 0.9256 - val_accuracy: 0.8728\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1affdad610>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BEST\n",
    "model3 = Sequential([\n",
    "    Dense(256, input_shape=(233,), activation='relu'),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "model3.compile(Adam(lr=.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model3.fit(scaled_train_samples, train_labels, validation_data=(scaled_val_samples, val_labels), \n",
    "          batch_size=10, epochs=15, shuffle=True, verbose=2, workers=8, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing .00001\n",
    "model2 = Sequential([\n",
    "    Dense(64, input_shape=(233,), activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "model2.compile(Adam(lr=.00001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model2.fit(scaled_train_samples, train_labels, validation_data=(scaled_val_samples, val_labels), \n",
    "          batch_size=10, epochs=15, shuffle=True, verbose=2, workers=8, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 190000 samples, validate on 11811 samples\n",
      "Epoch 1/15\n",
      " - 109s - loss: 0.3394 - accuracy: 0.8516 - val_loss: 0.4081 - val_accuracy: 0.8672\n",
      "Epoch 2/15\n",
      " - 103s - loss: 0.2667 - accuracy: 0.8897 - val_loss: 0.3416 - val_accuracy: 0.8987\n",
      "Epoch 3/15\n",
      " - 94s - loss: 0.2460 - accuracy: 0.8999 - val_loss: 0.6763 - val_accuracy: 0.7746\n",
      "Epoch 4/15\n",
      " - 93s - loss: 0.2336 - accuracy: 0.9058 - val_loss: 0.4247 - val_accuracy: 0.8811\n",
      "Epoch 5/15\n",
      " - 95s - loss: 0.2242 - accuracy: 0.9100 - val_loss: 0.6480 - val_accuracy: 0.8294\n",
      "Epoch 6/15\n",
      " - 93s - loss: 0.2177 - accuracy: 0.9127 - val_loss: 0.5598 - val_accuracy: 0.8297\n",
      "Epoch 7/15\n",
      " - 93s - loss: 0.2111 - accuracy: 0.9161 - val_loss: 0.5606 - val_accuracy: 0.8475\n",
      "Epoch 8/15\n",
      " - 93s - loss: 0.2053 - accuracy: 0.9183 - val_loss: 0.6970 - val_accuracy: 0.8059\n",
      "Epoch 9/15\n",
      " - 92s - loss: 0.2008 - accuracy: 0.9207 - val_loss: 0.6206 - val_accuracy: 0.8248\n",
      "Epoch 10/15\n",
      " - 93s - loss: 0.1970 - accuracy: 0.9221 - val_loss: 0.7241 - val_accuracy: 0.7805\n",
      "Epoch 11/15\n",
      " - 93s - loss: 0.1932 - accuracy: 0.9243 - val_loss: 0.4972 - val_accuracy: 0.8444\n",
      "Epoch 12/15\n",
      " - 94s - loss: 0.1891 - accuracy: 0.9255 - val_loss: 0.4967 - val_accuracy: 0.8555\n",
      "Epoch 13/15\n",
      " - 93s - loss: 0.1863 - accuracy: 0.9271 - val_loss: 0.6084 - val_accuracy: 0.7941\n",
      "Epoch 14/15\n",
      " - 92s - loss: 0.1829 - accuracy: 0.9280 - val_loss: 0.5523 - val_accuracy: 0.8390\n",
      "Epoch 15/15\n",
      " - 92s - loss: 0.1802 - accuracy: 0.9294 - val_loss: 0.5418 - val_accuracy: 0.8534\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1ae50deb10>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing \n",
    "model2 = Sequential([\n",
    "    Dense(64, input_shape=(233,), activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "model2.compile(Adam(lr=.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model2.fit(scaled_train_samples, train_labels, validation_data=(scaled_val_samples, val_labels), \n",
    "          batch_size=10, epochs=15, shuffle=True, verbose=2, workers=8, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[41507,  4011],\n",
       "       [ 1583,   142]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(scaled_test_samples, batch_size=10, verbose=0)\n",
    "rounded_predictions = model.predict_classes(scaled_test_samples, batch_size=10, verbose=0)\n",
    "cm = confusion_matrix(test_labels, rounded_predictions)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[42957,  2593],\n",
       "       [ 1582,   111]])"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(scaled_test_samples, batch_size=10, verbose=0)\n",
    "rounded_predictions = model.predict_classes(scaled_test_samples, batch_size=10, verbose=0)\n",
    "cm = confusion_matrix(test_labels, rounded_predictions)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[72729,   206],\n",
       "       [ 2246,   407]])"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(scaled_test_samples, batch_size=100, verbose=0)\n",
    "rounded_predictions = model.predict_classes(scaled_test_samples, batch_size=10, verbose=0)\n",
    "cm = confusion_matrix(test_labels, rounded_predictions)\n",
    "cm #dense 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[72697,   238],\n",
       "       [ 2219,   434]])"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(scaled_test_samples, batch_size=100, verbose=0)\n",
    "rounded_predictions = model.predict_classes(scaled_test_samples, batch_size=10, verbose=0)\n",
    "cm = confusion_matrix(test_labels, rounded_predictions)\n",
    "cm #batch 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[72664,   271],\n",
       "       [ 2192,   461]])"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(scaled_test_samples, batch_size=100, verbose=0)\n",
    "rounded_predictions = model.predict_classes(scaled_test_samples, batch_size=10, verbose=0)\n",
    "cm = confusion_matrix(test_labels, rounded_predictions)\n",
    "cm #1 dense layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[72585,   350],\n",
       "       [ 2054,   599]])"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(scaled_test_samples, batch_size=100, verbose=0)\n",
    "rounded_predictions = model.predict_classes(scaled_test_samples, batch_size=10, verbose=0)\n",
    "cm = confusion_matrix(test_labels, rounded_predictions)\n",
    "cm #batch_size=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[72666,   269],\n",
       "       [ 2147,   506]])"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(scaled_test_samples, batch_size=100, verbose=0)\n",
    "rounded_predictions = model.predict_classes(scaled_test_samples, batch_size=10, verbose=0)\n",
    "cm = confusion_matrix(test_labels, rounded_predictions)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[72744,   191],\n",
       "       [ 2272,   381]])"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(scaled_test_samples, batch_size=100, verbose=0)\n",
    "rounded_predictions = model.predict_classes(scaled_test_samples, batch_size=10, verbose=0)\n",
    "cm = confusion_matrix(test_labels, rounded_predictions)\n",
    "cm # lr=.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[72438,   497],\n",
       "       [ 1901,   752]])"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(scaled_test_samples, batch_size=100, verbose=0)\n",
    "rounded_predictions = model.predict_classes(scaled_test_samples, batch_size=10, verbose=0)\n",
    "cm = confusion_matrix(test_labels, rounded_predictions)\n",
    "cm # lr=.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### EXAMPLE CODE ####\n",
    "train_labels = np.array(train_labels)\n",
    "train_samples = np.array(train_samples)\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaled_train_samples = scaler.fit_transform(train_samples.reshape(-1,1))\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(16, input_shape=(1,), activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(Adam(lr=.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(scaled_train_samples, train_labels, validation_split=0.1, batch_size=5, epochs=20, shuffle=True, verbose=2, workers=4)\n",
    "\n",
    "###\n",
    "test_labels = np.array(test_labels)\n",
    "test_samples = np.array(test_samples)\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaled_test_samples = scaler.fit_transform((test_samples).reshape(-1,1))\n",
    "\n",
    "predictions = model.predict(scaled_test_samples, batch_size=10, verbose=0)\n",
    "rounded_predictions = model.predict_classes(scaled_test_samples, batch_size=10, verbose=0)\n",
    "\n",
    "###\n",
    "cm = confusion_matrix(test_labels, rounded_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle full dataset first\n",
    "# then split dataset for train, test, valid\n",
    "# pop off fraud for each data set \n",
    "# apply MinMaxScaler to training set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential([\n",
    "#     Dense(16, input_shape=(1,), activation='relu'),\n",
    "#     Dense(32, activation='relu'),\n",
    "#     Dense(2, activation='softmax')\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(16, input_shape())\n",
    "    \n",
    "])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
