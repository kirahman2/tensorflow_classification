{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import tempfile\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras.regularizers import l1\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.regularizers import L1L2\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.preprocessing import binarize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreProcessing():\n",
    "    def __init__(self, list_data, target):\n",
    "        self.target = target\n",
    "        self.train_sample = list_data[0].copy()\n",
    "        self.test_sample = list_data[1].copy()\n",
    "        self.test_sample = self.shuffle_data(self.test_sample)\n",
    "        self.test_sample, self.val_sample = self._split_test_data()\n",
    "        self.train_label = self._create_target(self.train_sample)\n",
    "        self.test_label = self._create_target(self.test_sample)\n",
    "        self.val_label = self._create_target(self.val_sample)\n",
    "        self.process_data()\n",
    "        \n",
    "    def process_data(self):\n",
    "        self._print_summary()\n",
    "        self._training_sets_array()\n",
    "        self._scale_data()\n",
    "        \n",
    "    def shuffle_data(self, dataset):\n",
    "        return shuffle(dataset).reset_index(drop=True)\n",
    "    \n",
    "    def _split_test_data(self):\n",
    "        return train_test_split(self.test_sample, test_size=.2)\n",
    "        \n",
    "    def _create_target(self, dataset):\n",
    "        return np.array(dataset.pop(self.target))\n",
    "        \n",
    "    def _print_summary(self):\n",
    "        print(\"Training data shape:\", self.train_sample.shape)\n",
    "        print(\"Testing data shape:\", self.test_sample.shape)\n",
    "        print(\"Validation data shape:\", self.val_sample.shape)\n",
    "        print(\"train_label length:\", self.train_label.shape[0])\n",
    "        print(\"test_label length:\", self.test_label.shape[0])\n",
    "        print(\"val_label length:\", self.val_label.shape[0])\n",
    "        \n",
    "    def _training_sets_array(self):\n",
    "        self.train_sample = np.array(self.train_sample)\n",
    "        self.test_sample = np.array(self.test_sample)\n",
    "        self.val_sample = np.array(self.val_sample)\n",
    "        \n",
    "    def _scale_data(self):\n",
    "        scaler = StandardScaler()\n",
    "        self.train_sample = scaler.fit_transform(self.train_sample)\n",
    "        self.test_sample = scaler.transform(self.test_sample)\n",
    "        self.val_sample = scaler.transform(self.val_sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CreateModel():\n",
    "    '''creates the model\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.filepath_chkpt = './cp.ckpt/'\n",
    "        self.train_sample = pp.train_sample\n",
    "        self.train_label = pp.train_label\n",
    "        self.test_sample = pp.test_sample\n",
    "        self.test_label = pp.test_label\n",
    "        self.val_sample = pp.val_sample\n",
    "        self.val_label = pp.val_label\n",
    "    \n",
    "    def _checkpoint_path(self):\n",
    "        checkpoint_path = \"./cp.ckpt/cp-{epoch:04d}.ckpt\"\n",
    "        return checkpoint_path\n",
    "    \n",
    "    def _define_checkpoint(self):\n",
    "        checkpoint_path = self._checkpoint_path()\n",
    "        cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, \n",
    "                                                         monitor='val_auc', \n",
    "                                                         verbose=1,\n",
    "                                                         save_best_only=False, \n",
    "                                                         save_weights_only=True,\n",
    "                                                         mode='max',\n",
    "                                                         save_freq='epoch')\n",
    "        return cp_callback\n",
    "    \n",
    "    def create_model(self, model, metrics, lr, loss):\n",
    "        'ingests and compiles model'\n",
    "        model.compile(optimizer=keras.optimizers.Adam(lr=lr), \n",
    "                      loss=loss, metrics=metrics)\n",
    "        return model\n",
    "    \n",
    "    def fit_model(self, model, epochs, fit_model=False):\n",
    "        if fit_model:\n",
    "            model = self._save_weights(model)\n",
    "            model.fit(self.train_sample, self.train_label, \n",
    "                      validation_data=(self.val_sample, self.val_label), \n",
    "                      batch_size=20, epochs=epochs, shuffle=True, verbose=2, \n",
    "                      workers=16, use_multiprocessing=True,\n",
    "                      callbacks=[cp_callback])\n",
    "            \n",
    "        if ~fit_model:\n",
    "            print(\"fit_model method is set to false.\")\n",
    "    \n",
    "    def _save_weights(self, model):\n",
    "        checkpoint_path = self._checkpoint_path()\n",
    "        model.save_weights(checkpoint_path.format(epoch=0))\n",
    "        return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TuneThreshold():\n",
    "    '''Fine tuning each epoch\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.current_thres = []\n",
    "        self.top_score = []\n",
    "        self.df_all_results = pd.DataFrame()\n",
    "        self.best_chkpt = []\n",
    "        self.best_threshold = []\n",
    "        \n",
    "    def tune_threshold(self, model):\n",
    "        y_pred = model.predict(pp.test_sample, batch_size=10, verbose=0)\n",
    "        \n",
    "        list_threshold = [.05, .1, .15, .2, .25, .3, .35, .4, .45, \n",
    "                          .5, .55, .6, .65, .7, .75, .8, .85, .9]\n",
    "        self._tune_thres_methods(list_threshold, y_pred)\n",
    "        list_tune_thres = self._fine_tune_thres()\n",
    "        self._tune_thres_methods(list_tune_thres, y_pred)\n",
    "        list_tune_thres = self._fine_tune_thres_2()\n",
    "        self._tune_thres_methods(list_tune_thres, y_pred)        \n",
    "        self._create_results_df()\n",
    "        self._save_best_thres()\n",
    "    \n",
    "        \n",
    "    def _tune_thres_methods(self, list_threshold, y_pred):\n",
    "        list_auc_score = self._calc_thres_score(list_threshold, y_pred)        \n",
    "        df_results = self._create_df_results(list_auc_score, list_threshold)\n",
    "        self._calc_best_score(df_results)\n",
    "        \n",
    "    def _calc_thres_score(self, list_threshold, y_pred):\n",
    "        list_auc_score = []\n",
    "        for thres in list_threshold:\n",
    "            y_pred_class = binarize(y_pred, thres)\n",
    "            fpr, tpr, thresholds = roc_curve(pp.test_label, \n",
    "                                             y_pred_class, \n",
    "                                             pos_label=1)\n",
    "            auc_score = auc(fpr, tpr)\n",
    "            list_auc_score.append(auc_score)\n",
    "        return list_auc_score\n",
    "    \n",
    "    def _create_df_results(self, list_auc_score, list_threshold):\n",
    "        col_thres = pd.Series(list_threshold, name='current_thres')\n",
    "        col_auc = pd.Series(list_auc_score, name='auc_score')\n",
    "        df_results = pd.concat([col_thres, col_auc], axis=1)\n",
    "        return df_results\n",
    "    \n",
    "    def _calc_best_score(self, df_results):\n",
    "        val_max_auc = df_results.auc_score.max()\n",
    "        df_max_auc = df_results[df_results.auc_score == val_max_auc]\n",
    "        df_max_auc_index = df_max_auc.index[0]\n",
    "        self.current_thres = df_results.loc[df_max_auc_index, 'current_thres']\n",
    "        self.top_score = val_max_auc \n",
    "    \n",
    "    def _fine_tune_thres(self):\n",
    "        list_tune_thres = []\n",
    "        temp_val_neg = self.current_thres\n",
    "        temp_val_pos = self.current_thres\n",
    "        for val in range(0,5):\n",
    "            temp_val_neg = temp_val_neg - .01\n",
    "            temp_val_pos = temp_val_pos + .01\n",
    "            list_tune_thres.append(round(temp_val_neg, 2))\n",
    "            list_tune_thres.append(round(temp_val_pos, 2))\n",
    "        list_tune_thres.append(round(self.current_thres, 2))    \n",
    "        list_tune_thres.sort()\n",
    "        return list_tune_thres\n",
    "    \n",
    "    def _fine_tune_thres_2(self):\n",
    "        list_tune_thres = []\n",
    "        temp_val_neg = self.current_thres\n",
    "        temp_val_pos = self.current_thres\n",
    "        for val in range(0,5):\n",
    "            temp_val_neg = temp_val_neg - .001\n",
    "            temp_val_pos = temp_val_pos + .001\n",
    "            list_tune_thres.append(round(temp_val_neg, 3))\n",
    "            list_tune_thres.append(round(temp_val_pos, 3))\n",
    "        list_tune_thres.append(round(self.current_thres, 3))    \n",
    "        list_tune_thres.sort()\n",
    "        return list_tune_thres\n",
    "    \n",
    "    def _create_results_df(self):\n",
    "        col_chkpt = pd.Series(sc.chkpt_num, name='chkpt_epoch')\n",
    "        col_thres = pd.Series(self.current_thres, name='best_threshold')\n",
    "        col_auc = pd.Series(self.top_score, name='auc_score')\n",
    "        df_temp = pd.concat([col_chkpt, col_thres, col_auc], axis=1)\n",
    "        print(df_temp)\n",
    "        self.df_all_results = pd.concat([self.df_all_results, df_temp], axis=0)\n",
    "        \n",
    "    def _save_best_thres(self):\n",
    "        dataset = self.df_all_results.copy()\n",
    "        val_best_auc = dataset.auc_score.max()\n",
    "        val_best_chkpt = dataset[dataset.auc_score==val_best_auc].chkpt_epoch\n",
    "        val_best_thres = dataset[dataset.auc_score==val_best_auc].best_threshold\n",
    "        self.best_chkpt = val_best_chkpt[0]\n",
    "        self.best_threshold = val_best_thres[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScoreCheckpoints():\n",
    "    '''Loading and testing each checkpoint\n",
    "    \n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.checkpoint_path = './cp.ckpt/'\n",
    "        self.list_auc_score = []\n",
    "        self.list_epoch = []\n",
    "        self.chkpt_num = []\n",
    "    \n",
    "    def create_chkpt_list(self):\n",
    "        list_checkpoints = []\n",
    "        for file in os.listdir(self.checkpoint_path):\n",
    "            val_checkpoint = file[0:12]\n",
    "            if file[0:3]=='cp-' and val_checkpoint not in list_checkpoints:\n",
    "                list_checkpoints.append(val_checkpoint)\n",
    "        list_checkpoints.sort()\n",
    "        return list_checkpoints\n",
    "    \n",
    "    def score_chkpts(self):\n",
    "        list_checkpoints = self.create_chkpt_list()\n",
    "        list_epoch = []\n",
    "        for chkpt in list_checkpoints[67:68]: # setting 66:67 for fast testing\n",
    "            filepath_chkpt = self.checkpoint_path + chkpt\n",
    "            model = mod.create_model(MODEL_SEQ, METRICS, LR, LOSS)\n",
    "            model.load_weights(filepath_chkpt)\n",
    "            rounded_predictions = model.predict_classes(pp.test_sample, batch_size=10, verbose=0)\n",
    "            auc_score = self._calc_chkpt_score(rounded_predictions)\n",
    "            self.chkpt_num = chkpt[3:7]\n",
    "            tt.tune_threshold(model)\n",
    "            self._plot_auc_scores()\n",
    "        # printing final dataframe results\n",
    "        print(tt.df_all_results)\n",
    "        self._plot_auc_scores()\n",
    "            \n",
    "    def _calc_chkpt_score(self, rounded_predictions):\n",
    "        fpr, tpr, thresholds = roc_curve(pp.test_label, rounded_predictions, pos_label=1)\n",
    "        # cm = confusion_matrix(pp.test_label, rounded_predictions) #not needed for now \n",
    "        auc_score = auc(fpr, tpr)\n",
    "        self.list_auc_score.append(auc_score)\n",
    "        return auc_score\n",
    "    \n",
    "    def _plot_auc_scores(self):\n",
    "        list_epoch = []\n",
    "        for val in range(1, len(self.list_auc_score) + 1):\n",
    "            list_epoch.append(val)\n",
    "        plt.plot(list_epoch, self.list_auc_score)\n",
    "        plt.title(\"Checkpoint Versus AUC Score\")\n",
    "        plt.ylabel(\"AUC Score\")\n",
    "        plt.xlabel(\"Checkpoint / Epoch\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class SaveModel():\n",
    "    def __init__(self):\n",
    "        self.chkpt_file_path = self._create_file_path()\n",
    "        self.saved_model_file_path = mod.filepath_chkpt + 'saved_model/'\n",
    "    \n",
    "    def _create_file_path(self):\n",
    "        chkpt_file_path = mod.filepath_chkpt + 'cp-' + tt.best_chkpt + '.ckpt'\n",
    "        return chkpt_file_path\n",
    "    \n",
    "    def save_best_model(self):\n",
    "        model = self._load_model_weights()\n",
    "        save_model_file_path = mod.filepath_chkpt + 'saved_model/' #delete this after fixing other bug\n",
    "        tf.saved_model.save(model, self.saved_model_file_path)\n",
    "    \n",
    "    def _load_model_weights(self):\n",
    "        model = mod.create_model(MODEL_SEQ, METRICS, LR, LOSS)\n",
    "        model.load_weights(self.chkpt_file_path)\n",
    "        return model\n",
    "        \n",
    "    def load_saved_model(self, summary=False):\n",
    "        model = tf.keras.models.load_model(self.saved_model_file_path)\n",
    "        if summary:\n",
    "            print('\\n')\n",
    "            print(model.summary())\n",
    "            print('\\n')\n",
    "        return model\n",
    "\n",
    "    def predict_binarize(self, model, test_data):\n",
    "        y_pred = model.predict(pp.test_sample, batch_size=10, verbose=0)\n",
    "        y_pred_class = binarize(y_pred, tt.best_threshold)\n",
    "        fpr, tpr, thresholds = roc_curve(pp.test_label, y_pred_class, pos_label=1)\n",
    "        auc_score = auc(fpr, tpr)\n",
    "        print('\\nauc for best model and best threshold:', auc_score)\n",
    "        return y_pred_class\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_data = '/Users/krahman/work/tutorials/tensorflow_classification/data/'\n",
    "\n",
    "df_raw = pd.read_csv(filepath_data + 'mod_x_train.csv').drop('Unnamed: 0', axis=1) #del once finished testing\n",
    "\n",
    "train_sample = pd.read_csv(filepath_data + 'mod_x_train.csv').drop('Unnamed: 0', axis=1)\n",
    "train_label = pd.read_csv(filepath_data + 'mod_y_train.csv').drop('Unnamed: 0', axis=1)\n",
    "train_sample = pd.concat([train_sample, train_label], axis=1)\n",
    "test_sample = pd.read_csv(filepath_data + 'mod_x_test.csv').drop('Unnamed: 0', axis=1)\n",
    "test_label = pd.read_csv(filepath_data + 'mod_y_test.csv').drop('index', axis=1)\n",
    "test_sample = pd.concat([test_sample, test_label], axis=1)\n",
    "\n",
    "target = '0'\n",
    "\n",
    "list_data = [train_sample, test_sample]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate PreProcessing Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (190000, 233)\n",
      "Testing data shape: (47243, 233)\n",
      "Validation data shape: (11811, 233)\n",
      "train_label length: 190000\n",
      "test_label length: 47243\n",
      "val_label length: 11811\n"
     ]
    }
   ],
   "source": [
    "pp = PreProcessing(list_data, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate CreateModel Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = CreateModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Neural Network Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_TRAIN = pp.train_sample\n",
    "\n",
    "neg, pos = np.bincount(train_sample[target])\n",
    "initial_bias = np.log([pos/neg])\n",
    "OUTPUT_BIAS = tf.keras.initializers.Constant(initial_bias)\n",
    "LOSS = keras.losses.BinaryCrossentropy()\n",
    "LR = .0001\n",
    "METRICS = [keras.metrics.AUC(name='auc'),\n",
    "           keras.metrics.FalsePositives(name='fp'),\n",
    "           keras.metrics.FalseNegatives(name='fn')]\n",
    "\n",
    "MODEL_SEQ = keras.Sequential([keras.layers.Dense(256, activation='relu', kernel_regularizer=l2(0.0001), input_shape=(DF_TRAIN.shape[-1],)),\n",
    "                              keras.layers.Dense(256, activation='relu', kernel_regularizer=l2(0.0001)),\n",
    "                              keras.layers.Dense(256, activation='relu', kernel_regularizer=l2(0.0001)),\n",
    "                              keras.layers.Dense(256, activation='relu', kernel_regularizer=l2(0.0001)),\n",
    "                              keras.layers.Dense(256, activation='relu', kernel_regularizer=l2(0.0001)),\n",
    "                              keras.layers.Dense(256, activation='relu', kernel_regularizer=l2(0.0001)),\n",
    "                              keras.layers.Dense(256, activation='relu', kernel_regularizer=l2(0.0001)),\n",
    "                              keras.layers.Dense(256, activation='relu', kernel_regularizer=l2(0.0001)),\n",
    "                              keras.layers.Dense(256, activation='relu', kernel_regularizer=l2(0.0001)),\n",
    "                              keras.layers.Dropout(.5),\n",
    "                              keras.layers.Dense(1, activation='sigmoid', bias_initializer=OUTPUT_BIAS)])\n",
    "\n",
    "# MODEL_SEQ = keras.Sequential([keras.layers.Dense(16, activation='relu', kernel_regularizer=l2(0.0001), input_shape=(DF_TRAIN.shape[-1],)),\n",
    "#                           keras.layers.Dense(16, activation='relu', kernel_regularizer=l2(0.0001)),\n",
    "#                           keras.layers.Dropout(.5),\n",
    "#                           keras.layers.Dense(1, activation='sigmoid', bias_initializer=OUTPUT_BIAS)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mod.create_model(MODEL_SEQ, METRICS, LR, LOSS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_model method is set to false.\n"
     ]
    }
   ],
   "source": [
    "mod.fit_model(model, epochs=100, fit_model=False) #comment out until next fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate TuneThreshold Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = TuneThreshold()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate ScoreCheckpoints Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = ScoreCheckpoints()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  chkpt_epoch  best_threshold  auc_score\n",
      "0        0067           0.168   0.867784\n",
      "  chkpt_epoch  best_threshold  auc_score\n",
      "0        0067           0.168   0.867784\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "list_checkpoints = sc.create_chkpt_list()\n",
    "sc.score_chkpts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/alpha/guide/checkpoints#loading_mechanics for details.\n",
      "WARNING:tensorflow:From /Users/krahman/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: ./cp.ckpt/saved_model/assets\n",
      "\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 256)               59904     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 586,497\n",
      "Trainable params: 586,497\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "\n",
      "\n",
      "auc for best model and best threshold: 0.8677835633478899\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       ...,\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm = SaveModel()\n",
    "sm.save_best_model()\n",
    "model_1 = sm.load_saved_model(summary=True)\n",
    "y_pred = sm.predict_binarize(model_1, pp.test_sample)\n",
    "y_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
