{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "# import random as rn\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dropout\n",
    "from keras.layers.core import Dense, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import categorical_crossentropy\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import *\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "filepath_files = '/Users/krahman/work/tutorials/tensorflow_classification/data/'\n",
    "\n",
    "train_samples = pd.read_csv(filepath_files + 'mod_x_train.csv').drop('Unnamed: 0', axis=1)\n",
    "train_labels = pd.read_csv(filepath_files + 'mod_y_train.csv').drop('Unnamed: 0', axis=1)\n",
    "test_samples = pd.read_csv(filepath_files + 'mod_x_test.csv').drop('Unnamed: 0', axis=1)\n",
    "test_labels = pd.read_csv(filepath_files + 'mod_y_test.csv').drop('470624', axis=1)\n",
    "test_labels = test_labels.rename(columns={\"0\":\"isFraud\"})\n",
    "\n",
    "test_samples = pd.concat([test_samples, test_labels], axis=1)\n",
    "test_samples, val_samples = train_test_split(test_samples, test_size=.4)\n",
    "\n",
    "train_samples = train_samples.reset_index(drop=True)\n",
    "test_samples = test_samples.reset_index(drop=True)\n",
    "val_samples = val_samples.reset_index(drop=True)\n",
    "\n",
    "# test_samples = test_samples.drop(test_samples.tail(3).index)\n",
    "# val_samples = val_samples.drop(val_samples.tail(1).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = train_labels.pop('0')\n",
    "test_labels = test_samples.pop('isFraud')\n",
    "val_labels = val_samples.pop('isFraud')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(190000, 233)\n",
      "(23622, 233)\n",
      "(35432, 233)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training data shape:\", train_samples.shape)\n",
    "print(\"Validation data shape:\", val_samples.shape)\n",
    "print(\"Testing data shape:\", test_samples.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = np.array(train_labels.astype(int))\n",
    "test_labels = np.array(test_labels.fillna(0).astype(int))\n",
    "val_labels = np.array(val_labels.astype(int))\n",
    "\n",
    "train_samples = np.array(train_samples)\n",
    "test_samples = np.array(test_samples)\n",
    "val_samples = np.array(val_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaled_train_samples = scaler.fit_transform(train_samples)#.reshape(-1,1))\n",
    "scaled_test_samples = scaler.fit_transform(test_samples)#.reshape(-1,1))\n",
    "scaled_val_samples = scaler.fit_transform(val_samples)#.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################### testing \n",
    "loss = keras.losses.BinaryCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 190000 samples, validate on 23622 samples\n",
      "Epoch 1/10\n",
      " - 66s - loss: 7.6666 - auc: 0.5000 - fp: 95000.0000 - fn: 0.0000e+00 - val_loss: 14.7873 - val_auc: 0.5000 - val_fp: 22781.0000 - val_fn: 0.0000e+00\n",
      "Epoch 2/10\n",
      " - 62s - loss: 7.6666 - auc: 0.5000 - fp: 95000.0000 - fn: 0.0000e+00 - val_loss: 14.7873 - val_auc: 0.5000 - val_fp: 22781.0000 - val_fn: 0.0000e+00\n",
      "Epoch 3/10\n",
      " - 57s - loss: 7.6666 - auc: 0.5000 - fp: 95000.0000 - fn: 0.0000e+00 - val_loss: 14.7873 - val_auc: 0.5000 - val_fp: 22781.0000 - val_fn: 0.0000e+00\n",
      "Epoch 4/10\n"
     ]
    }
   ],
   "source": [
    "# testing workers, next test metrics\n",
    "metrics = [keras.metrics.AUC(name='auc'),\n",
    "           keras.metrics.FalsePositives(name='fp'),\n",
    "           keras.metrics.FalseNegatives(name='fn')]\n",
    "\n",
    "batch_size = 10\n",
    "epochs = 10\n",
    "lr = .0001\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(16, input_shape=(233,), activation='relu'),\n",
    "    Dense(1, activation='softmax')\n",
    "])\n",
    "model.compile(Adam(lr=lr), loss=loss, metrics=metrics)\n",
    "model.fit(scaled_train_samples, train_labels, validation_data=(scaled_val_samples, val_labels), \n",
    "          batch_size=batch_size, epochs=epochs, shuffle=True, verbose=2, workers=4, use_multiprocessing=True)\n",
    "\n",
    "predictions = model.predict(scaled_test_samples, batch_size=10, verbose=0)\n",
    "rounded_predictions = model.predict_classes(scaled_test_samples, batch_size=10, verbose=0)\n",
    "cm = confusion_matrix(test_labels, rounded_predictions)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing workers\n",
    "metrics = [keras.metrics.AUC(name='auc'),\n",
    "           keras.metrics.FalsePositives(name='fp'),\n",
    "           keras.metrics.FalseNegatives(name='fn')]\n",
    "\n",
    "batch_size = 10\n",
    "epochs = 10\n",
    "lr = .0001\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(16, input_shape=(233,), activation='relu'),\n",
    "    Dense(1, activation='softmax')\n",
    "])\n",
    "model.compile(Adam(lr=lr), loss=loss, metrics=metrics)\n",
    "model.fit(scaled_train_samples, train_labels, validation_data=(scaled_val_samples, val_labels), \n",
    "          batch_size=batch_size, epochs=epochs, shuffle=True, verbose=2, workers=1, use_multiprocessing=True)\n",
    "\n",
    "predictions = model.predict(scaled_test_samples, batch_size=10, verbose=0)\n",
    "rounded_predictions = model.predict_classes(scaled_test_samples, batch_size=10, verbose=0)\n",
    "cm = confusion_matrix(test_labels, rounded_predictions)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 190000 samples, validate on 23622 samples\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/krahman/opt/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-240-6ea8923af3ee>\", line 25, in <module>\n",
      "    batch_size=batch_size, epochs=epochs, shuffle=True, verbose=2, workers=8, use_multiprocessing=True)\n",
      "  File \"/Users/krahman/opt/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\", line 1239, in fit\n",
      "    validation_freq=validation_freq)\n",
      "  File \"/Users/krahman/opt/anaconda3/lib/python3.7/site-packages/keras/engine/training_arrays.py\", line 196, in fit_loop\n",
      "    outs = fit_function(ins_batch)\n",
      "  File \"/Users/krahman/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\", line 3740, in __call__\n",
      "    outputs = self._graph_fn(*converted_inputs)\n",
      "  File \"/Users/krahman/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 1081, in __call__\n",
      "    return self._call_impl(args, kwargs)\n",
      "  File \"/Users/krahman/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 1121, in _call_impl\n",
      "    return self._call_flat(args, self.captured_inputs, cancellation_manager)\n",
      "  File \"/Users/krahman/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 1224, in _call_flat\n",
      "    ctx, args, cancellation_manager=cancellation_manager)\n",
      "  File \"/Users/krahman/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 511, in call\n",
      "    ctx=ctx)\n",
      "  File \"/Users/krahman/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\", line 61, in quick_execute\n",
      "    num_outputs)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/krahman/opt/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2040, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/krahman/opt/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/Users/krahman/opt/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/krahman/opt/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/Users/krahman/opt/anaconda3/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/Users/krahman/opt/anaconda3/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/Users/krahman/opt/anaconda3/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/Users/krahman/opt/anaconda3/lib/python3.7/inspect.py\", line 725, in getmodule\n",
      "    file = getabsfile(object, _filename)\n",
      "  File \"/Users/krahman/opt/anaconda3/lib/python3.7/inspect.py\", line 709, in getabsfile\n",
      "    return os.path.normcase(os.path.abspath(_filename))\n",
      "  File \"/Users/krahman/opt/anaconda3/lib/python3.7/posixpath.py\", line 383, in abspath\n",
      "    cwd = os.getcwd()\n",
      "PermissionError: [Errno 1] Operation not permitted\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "metrics = [keras.metrics.AUC(name='auc'),\n",
    "           keras.metrics.FalsePositives(name='fp'),\n",
    "           keras.metrics.FalseNegatives(name='fn')]\n",
    "\n",
    "batch_size = 10\n",
    "epochs = 3\n",
    "lr = .000001\n",
    "lr = .01\n",
    "\n",
    "model3 = Sequential([\n",
    "    Dense(512, input_shape=(233,), activation='relu'),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='softmax')\n",
    "])\n",
    "model3.compile(Adam(lr=lr), loss=loss, metrics=metrics)\n",
    "model3.fit(scaled_train_samples, train_labels, validation_data=(scaled_val_samples, val_labels), \n",
    "          batch_size=batch_size, epochs=epochs, shuffle=True, verbose=2, workers=4, use_multiprocessing=True)\n",
    "\n",
    "predictions = model3.predict(scaled_test_samples, batch_size=10, verbose=0)\n",
    "rounded_predictions = model3.predict_classes(scaled_test_samples, batch_size=10, verbose=0)\n",
    "cm = confusion_matrix(test_labels, rounded_predictions)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 190000 samples, validate on 11811 samples\n",
      "Epoch 1/15\n",
      " - 217s - loss: 0.3056 - accuracy: 0.8685 - val_loss: 0.3789 - val_accuracy: 0.9004\n",
      "Epoch 2/15\n",
      " - 215s - loss: 0.2416 - accuracy: 0.9009 - val_loss: 0.4035 - val_accuracy: 0.8996\n",
      "Epoch 3/15\n",
      " - 215s - loss: 0.2200 - accuracy: 0.9112 - val_loss: 0.4145 - val_accuracy: 0.8894\n",
      "Epoch 4/15\n",
      " - 215s - loss: 0.2051 - accuracy: 0.9178 - val_loss: 0.4427 - val_accuracy: 0.8854\n",
      "Epoch 5/15\n",
      " - 235s - loss: 0.1941 - accuracy: 0.9224 - val_loss: 0.4560 - val_accuracy: 0.8824\n",
      "Epoch 6/15\n",
      " - 215s - loss: 0.1839 - accuracy: 0.9267 - val_loss: 0.5035 - val_accuracy: 0.8733\n",
      "Epoch 7/15\n",
      " - 215s - loss: 0.1762 - accuracy: 0.9307 - val_loss: 0.5650 - val_accuracy: 0.8870\n",
      "Epoch 8/15\n",
      " - 216s - loss: 0.1690 - accuracy: 0.9343 - val_loss: 0.7868 - val_accuracy: 0.8779\n",
      "Epoch 9/15\n",
      " - 215s - loss: 0.1631 - accuracy: 0.9365 - val_loss: 0.7460 - val_accuracy: 0.8504\n",
      "Epoch 10/15\n",
      " - 216s - loss: 0.1577 - accuracy: 0.9385 - val_loss: 0.8295 - val_accuracy: 0.8385\n",
      "Epoch 11/15\n",
      " - 216s - loss: 0.1531 - accuracy: 0.9410 - val_loss: 0.8204 - val_accuracy: 0.8689\n",
      "Epoch 12/15\n",
      " - 215s - loss: 0.1485 - accuracy: 0.9429 - val_loss: 0.8675 - val_accuracy: 0.8364\n",
      "Epoch 13/15\n",
      " - 214s - loss: 0.1441 - accuracy: 0.9442 - val_loss: 0.8762 - val_accuracy: 0.8562\n",
      "Epoch 14/15\n",
      " - 214s - loss: 0.1400 - accuracy: 0.9459 - val_loss: 1.0218 - val_accuracy: 0.8612\n",
      "Epoch 15/15\n",
      " - 216s - loss: 0.1363 - accuracy: 0.9473 - val_loss: 0.9056 - val_accuracy: 0.8253\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1af7bfe310>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing\n",
    "model3 = Sequential([\n",
    "    Dense(256, input_shape=(233,), activation='relu'),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "model3.compile(Adam(lr=.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model3.fit(scaled_train_samples, train_labels, validation_data=(scaled_val_samples, val_labels), \n",
    "          batch_size=10, epochs=15, shuffle=True, verbose=2, workers=8, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 190000 samples, validate on 11811 samples\n",
      "Epoch 1/10\n",
      " - 219s - loss: 0.3035 - accuracy: 0.8689 - val_loss: 0.2884 - val_accuracy: 0.9268\n",
      "Epoch 2/10\n",
      " - 282s - loss: 0.2410 - accuracy: 0.9009 - val_loss: 0.3550 - val_accuracy: 0.8940\n",
      "Epoch 3/10\n",
      " - 224s - loss: 0.2197 - accuracy: 0.9111 - val_loss: 0.3425 - val_accuracy: 0.9085\n",
      "Epoch 4/10\n",
      " - 218s - loss: 0.2038 - accuracy: 0.9185 - val_loss: 0.3719 - val_accuracy: 0.8928\n",
      "Epoch 5/10\n",
      " - 237s - loss: 0.1916 - accuracy: 0.9240 - val_loss: 0.4116 - val_accuracy: 0.8882\n",
      "Epoch 6/10\n",
      " - 230s - loss: 0.1819 - accuracy: 0.9283 - val_loss: 0.4760 - val_accuracy: 0.8866\n",
      "Epoch 7/10\n",
      " - 228s - loss: 0.1743 - accuracy: 0.9317 - val_loss: 0.4758 - val_accuracy: 0.8853\n",
      "Epoch 8/10\n",
      " - 282s - loss: 0.1674 - accuracy: 0.9346 - val_loss: 0.4777 - val_accuracy: 0.8734\n",
      "Epoch 9/10\n",
      " - 255s - loss: 0.1611 - accuracy: 0.9377 - val_loss: 0.5180 - val_accuracy: 0.8962\n",
      "Epoch 10/10\n",
      " - 264s - loss: 0.1564 - accuracy: 0.9396 - val_loss: 0.5364 - val_accuracy: 0.8836\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[41558,  4014],\n",
       "       [ 1520,   151]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BEST\n",
    "model3 = Sequential([\n",
    "    Dense(256, input_shape=(233,), activation='relu'),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "model3.compile(Adam(lr=.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model3.fit(scaled_train_samples, train_labels, validation_data=(scaled_val_samples, val_labels), \n",
    "          batch_size=10, epochs=10, shuffle=True, verbose=2, workers=8, use_multiprocessing=True)\n",
    "\n",
    "predictions = model3.predict(scaled_test_samples, batch_size=10, verbose=0)\n",
    "rounded_predictions = model3.predict_classes(scaled_test_samples, batch_size=10, verbose=0)\n",
    "cm = confusion_matrix(test_labels, rounded_predictions)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 190000 samples, validate on 11811 samples\n",
      "Epoch 1/10\n",
      " - 271s - loss: 0.3938 - accuracy: 0.8214 - val_loss: 0.3914 - val_accuracy: 0.8572\n",
      "Epoch 2/10\n",
      " - 265s - loss: 0.2804 - accuracy: 0.8833 - val_loss: 0.4753 - val_accuracy: 0.8328\n",
      "Epoch 3/10\n",
      " - 274s - loss: 0.2562 - accuracy: 0.8957 - val_loss: 0.3714 - val_accuracy: 0.8996\n",
      "Epoch 4/10\n",
      " - 280s - loss: 0.2413 - accuracy: 0.9030 - val_loss: 0.3650 - val_accuracy: 0.9076\n",
      "Epoch 5/10\n",
      " - 266s - loss: 0.2311 - accuracy: 0.9076 - val_loss: 0.3622 - val_accuracy: 0.9145\n",
      "Epoch 6/10\n",
      " - 332s - loss: 0.2235 - accuracy: 0.9109 - val_loss: 0.3747 - val_accuracy: 0.9116\n",
      "Epoch 7/10\n",
      " - 303s - loss: 0.2167 - accuracy: 0.9141 - val_loss: 0.3681 - val_accuracy: 0.9222\n",
      "Epoch 8/10\n",
      " - 305s - loss: 0.2111 - accuracy: 0.9169 - val_loss: 0.3811 - val_accuracy: 0.9230\n",
      "Epoch 9/10\n",
      " - 303s - loss: 0.2066 - accuracy: 0.9184 - val_loss: 0.3763 - val_accuracy: 0.9257\n",
      "Epoch 10/10\n",
      " - 295s - loss: 0.2015 - accuracy: 0.9211 - val_loss: 0.3689 - val_accuracy: 0.9279\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[42868,  2704],\n",
       "       [ 1565,   106]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BEST\n",
    "model3 = Sequential([\n",
    "    Dense(256, input_shape=(233,), activation='relu'),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "model3.compile(Adam(lr=.00001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model3.fit(scaled_train_samples, train_labels, validation_data=(scaled_val_samples, val_labels), \n",
    "          batch_size=10, epochs=10, shuffle=True, verbose=2, workers=8, use_multiprocessing=True)\n",
    "\n",
    "predictions = model3.predict(scaled_test_samples, batch_size=10, verbose=0)\n",
    "rounded_predictions = model3.predict_classes(scaled_test_samples, batch_size=10, verbose=0)\n",
    "cm = confusion_matrix(test_labels, rounded_predictions)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 190000 samples, validate on 11811 samples\n",
      "Epoch 1/10\n",
      " - 205s - loss: 0.3026 - accuracy: 0.8688 - val_loss: 0.9822 - val_accuracy: 0.6884\n",
      "Epoch 2/10\n",
      " - 212s - loss: 0.2402 - accuracy: 0.9015 - val_loss: 1.2454 - val_accuracy: 0.5444\n",
      "Epoch 3/10\n",
      " - 196s - loss: 0.2213 - accuracy: 0.9104 - val_loss: 0.7317 - val_accuracy: 0.7308\n",
      "Epoch 4/10\n",
      " - 206s - loss: 0.2070 - accuracy: 0.9167 - val_loss: 1.1737 - val_accuracy: 0.7072\n",
      "Epoch 5/10\n",
      " - 204s - loss: 0.1956 - accuracy: 0.9220 - val_loss: 0.7927 - val_accuracy: 0.7717\n",
      "Epoch 6/10\n",
      " - 194s - loss: 0.1857 - accuracy: 0.9267 - val_loss: 1.1894 - val_accuracy: 0.6619\n",
      "Epoch 7/10\n",
      " - 202s - loss: 0.1774 - accuracy: 0.9301 - val_loss: 0.9937 - val_accuracy: 0.7533\n",
      "Epoch 8/10\n",
      " - 202s - loss: 0.1699 - accuracy: 0.9330 - val_loss: 1.3999 - val_accuracy: 0.7167\n",
      "Epoch 9/10\n",
      " - 194s - loss: 0.1640 - accuracy: 0.9350 - val_loss: 0.7933 - val_accuracy: 0.8282\n",
      "Epoch 10/10\n",
      " - 204s - loss: 0.1585 - accuracy: 0.9381 - val_loss: 1.0263 - val_accuracy: 0.8193\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x128ce3f10>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BEST testing .0001\n",
    "model7 = Sequential([\n",
    "    Dense(256, input_shape=(233,), activation='relu'),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "model7.compile(Adam(lr=.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model7.fit(scaled_train_samples, train_labels, validation_data=(scaled_val_samples, val_labels), \n",
    "          batch_size=10, epochs=10, shuffle=True, verbose=2, workers=4, use_multiprocessing=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
