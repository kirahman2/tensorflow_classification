{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import tempfile\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras.regularizers import l1\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.regularizers import L1L2\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.preprocessing import binarize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# smote and upsampling + validation set pulled from training set (now we have data leakage)\n",
    "# filepath_data = '/Users/krahman/work/tutorials/tensorflow_classification/data/'\n",
    "\n",
    "# df_raw = pd.read_csv(filepath_data + 'mod_x_train.csv').drop('Unnamed: 0', axis=1) #del once finished testing\n",
    "\n",
    "# train_sample = pd.read_csv(filepath_data + 'mod_x_train.csv').drop('Unnamed: 0', axis=1)\n",
    "# train_label = pd.read_csv(filepath_data + 'mod_y_train.csv').drop('Unnamed: 0', axis=1)\n",
    "# train_sample = pd.concat([train_sample, train_label], axis=1)\n",
    "# test_sample = pd.read_csv(filepath_data + 'mod_x_test.csv').drop('Unnamed: 0', axis=1)\n",
    "# test_label = pd.read_csv(filepath_data + 'mod_y_test.csv').drop('index', axis=1)\n",
    "# test_sample = pd.concat([test_sample, test_label], axis=1)\n",
    "\n",
    "# target = '0'\n",
    "\n",
    "# list_data = [train_sample, test_sample]\n",
    "\n",
    "class PreProcessing():\n",
    "    def __init__(self, list_data, target):\n",
    "        self.target = target\n",
    "        self.train_sample = list_data[0].copy()\n",
    "        self.test_sample = list_data[1].copy()\n",
    "        self.test_sample = self.shuffle_data(self.test_sample)\n",
    "        self.test_sample, self.val_sample = self._split_test_data()\n",
    "        self.train_label = self._create_target(self.train_sample)\n",
    "        self.test_label = self._create_target(self.test_sample)\n",
    "        self.val_label = self._create_target(self.val_sample)\n",
    "        self.process_data()\n",
    "        \n",
    "    def process_data(self):\n",
    "        self._print_summary()\n",
    "        self._training_sets_array()\n",
    "        self._scale_data()\n",
    "        \n",
    "    def shuffle_data(self, dataset):\n",
    "        return shuffle(dataset).reset_index(drop=True)\n",
    "    \n",
    "    def _split_test_data(self):\n",
    "        return train_test_split(self.test_sample, test_size=.2)\n",
    "        \n",
    "    def _create_target(self, dataset):\n",
    "        return np.array(dataset.pop(self.target))\n",
    "        \n",
    "    def _print_summary(self):\n",
    "        print(\"Training data shape:\", self.train_sample.shape)\n",
    "        print(\"Testing data shape:\", self.test_sample.shape)\n",
    "        print(\"Validation data shape:\", self.val_sample.shape)\n",
    "        print(\"train_label length:\", self.train_label.shape[0])\n",
    "        print(\"test_label length:\", self.test_label.shape[0])\n",
    "        print(\"val_label length:\", self.val_label.shape[0])\n",
    "        \n",
    "    def _training_sets_array(self):\n",
    "        self.train_sample = np.array(self.train_sample)\n",
    "        self.test_sample = np.array(self.test_sample)\n",
    "        self.val_sample = np.array(self.val_sample)\n",
    "        \n",
    "    def _scale_data(self):\n",
    "        scaler = StandardScaler()\n",
    "        self.train_sample = scaler.fit_transform(self.train_sample)\n",
    "        self.test_sample = scaler.transform(self.test_sample)\n",
    "        self.val_sample = scaler.transform(self.val_sample)\n",
    "\n",
    "# pp = PreProcessing(list_data, target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# import numpy as np \n",
    "# from tensorflow import keras\n",
    "# from tensorflow.keras.regularizers import l2\n",
    "\n",
    "class CreateModel():\n",
    "    '''creates the model\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.filepath_chkpt = './cp.ckpt/'\n",
    "        self.train_sample = pp.train_sample\n",
    "        self.train_label = pp.train_label\n",
    "        self.test_sample = pp.test_sample\n",
    "        self.test_label = pp.test_label\n",
    "        self.val_sample = pp.val_sample\n",
    "        self.val_label = pp.val_label\n",
    "    \n",
    "    def _checkpoint_path(self):\n",
    "        checkpoint_path = \"./cp.ckpt/cp-{epoch:04d}.ckpt\"\n",
    "        return checkpoint_path\n",
    "    \n",
    "    def _define_checkpoint(self):\n",
    "        checkpoint_path = self._checkpoint_path()\n",
    "        cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, \n",
    "                                                         monitor='val_auc', \n",
    "                                                         verbose=1,\n",
    "                                                         save_best_only=False, \n",
    "                                                         save_weights_only=True,\n",
    "                                                         mode='max',\n",
    "                                                         save_freq='epoch')\n",
    "        return cp_callback\n",
    "    \n",
    "    def create_model(self, model, metrics, lr, loss):\n",
    "        'ingests and compiles model'\n",
    "        model.compile(optimizer=keras.optimizers.Adam(lr=lr), \n",
    "                      loss=loss, metrics=metrics)\n",
    "        return model\n",
    "    \n",
    "    def fit_model(self, model, epochs, fit_model=False):\n",
    "        if fit_model:\n",
    "            model = self._save_weights(model)\n",
    "            model.fit(self.train_sample, self.train_label, \n",
    "                      validation_data=(self.val_sample, self.val_label), \n",
    "                      batch_size=20, epochs=epochs, shuffle=True, verbose=2, \n",
    "                      workers=16, use_multiprocessing=True,\n",
    "                      callbacks=[cp_callback])\n",
    "            \n",
    "        if ~fit_model:\n",
    "            print(\"fit_model method is set to false.\")\n",
    "    \n",
    "    def _save_weights(self, model):\n",
    "        checkpoint_path = self._checkpoint_path()\n",
    "        model.save_weights(checkpoint_path.format(epoch=0))\n",
    "        return model\n",
    "    \n",
    "# mod = CreateModel()\n",
    "# ###########################\n",
    "# ##### hard code below #####\n",
    "\n",
    "# DF_TRAIN = pp.train_sample\n",
    "\n",
    "# ##### Defining Model Parameters #####\n",
    "# neg, pos = np.bincount(train_sample[target])\n",
    "# initial_bias = np.log([pos/neg])\n",
    "# OUTPUT_BIAS = tf.keras.initializers.Constant(initial_bias)\n",
    "# LOSS = keras.losses.BinaryCrossentropy()\n",
    "# LR = .0001\n",
    "# METRICS = [keras.metrics.AUC(name='auc'),\n",
    "#            keras.metrics.FalsePositives(name='fp'),\n",
    "#            keras.metrics.FalseNegatives(name='fn')]\n",
    "\n",
    "# MODEL_SEQ = keras.Sequential([keras.layers.Dense(256, activation='relu', kernel_regularizer=l2(0.0001), input_shape=(pp.train_sample.shape[-1],)),\n",
    "#                               keras.layers.Dense(256, activation='relu', kernel_regularizer=l2(0.0001)),\n",
    "#                               keras.layers.Dense(256, activation='relu', kernel_regularizer=l2(0.0001)),\n",
    "#                               keras.layers.Dense(256, activation='relu', kernel_regularizer=l2(0.0001)),\n",
    "#                               keras.layers.Dense(256, activation='relu', kernel_regularizer=l2(0.0001)),\n",
    "#                               keras.layers.Dense(256, activation='relu', kernel_regularizer=l2(0.0001)),\n",
    "#                               keras.layers.Dense(256, activation='relu', kernel_regularizer=l2(0.0001)),\n",
    "#                               keras.layers.Dense(256, activation='relu', kernel_regularizer=l2(0.0001)),\n",
    "#                               keras.layers.Dense(256, activation='relu', kernel_regularizer=l2(0.0001)),\n",
    "#                               keras.layers.Dropout(.5),\n",
    "#                               keras.layers.Dense(1, activation='sigmoid', bias_initializer=OUTPUT_BIAS)])\n",
    "\n",
    "# # MODEL_SEQ = keras.Sequential([keras.layers.Dense(16, activation='relu', kernel_regularizer=l2(0.0001), input_shape=(DF_TRAIN.shape[-1],)),\n",
    "# #                           keras.layers.Dense(16, activation='relu', kernel_regularizer=l2(0.0001)),\n",
    "# #                           keras.layers.Dropout(.5),\n",
    "# #                           keras.layers.Dense(1, activation='sigmoid', bias_initializer=OUTPUT_BIAS)])\n",
    "\n",
    "\n",
    "# model = mod.create_model(MODEL_SEQ, METRICS, LR, LOSS)\n",
    "# mod.fit_model(model, epochs=100, fit_model=False) #comment out until next fitting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import binarize\n",
    "# from sklearn.metrics import roc_curve\n",
    "# from sklearn.metrics import auc\n",
    "# import pandas as pd\n",
    "\n",
    "class TuneThreshold():\n",
    "    '''Fine tuning each epoch\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.current_thres = []\n",
    "        self.top_score = []\n",
    "        self.df_all_results = pd.DataFrame()\n",
    "        self.best_chkpt = []\n",
    "        self.best_threshold = []\n",
    "        \n",
    "    def tune_threshold(self, model):\n",
    "        y_pred = model.predict(pp.test_sample, batch_size=10, verbose=0)\n",
    "        \n",
    "        list_threshold = [.05, .1, .15, .2, .25, .3, .35, .4, .45, \n",
    "                          .5, .55, .6, .65, .7, .75, .8, .85, .9]\n",
    "        self._tune_thres_methods(list_threshold, y_pred)\n",
    "        list_tune_thres = self._fine_tune_thres()\n",
    "        self._tune_thres_methods(list_tune_thres, y_pred)\n",
    "        list_tune_thres = self._fine_tune_thres_2()\n",
    "        self._tune_thres_methods(list_tune_thres, y_pred)        \n",
    "        self._create_results_df()\n",
    "        self._save_best_thres()\n",
    "    \n",
    "        \n",
    "    def _tune_thres_methods(self, list_threshold, y_pred):\n",
    "        list_auc_score = self._calc_thres_score(list_threshold, y_pred)        \n",
    "        df_results = self._create_df_results(list_auc_score, list_threshold)\n",
    "        self._calc_best_score(df_results)\n",
    "        \n",
    "    def _calc_thres_score(self, list_threshold, y_pred):\n",
    "        list_auc_score = []\n",
    "        for thres in list_threshold:\n",
    "            y_pred_class = binarize(y_pred, thres)\n",
    "            fpr, tpr, thresholds = roc_curve(pp.test_label, \n",
    "                                             y_pred_class, \n",
    "                                             pos_label=1)\n",
    "            auc_score = auc(fpr, tpr)\n",
    "            list_auc_score.append(auc_score)\n",
    "        return list_auc_score\n",
    "    \n",
    "    def _create_df_results(self, list_auc_score, list_threshold):\n",
    "        col_thres = pd.Series(list_threshold, name='current_thres')\n",
    "        col_auc = pd.Series(list_auc_score, name='auc_score')\n",
    "        df_results = pd.concat([col_thres, col_auc], axis=1)\n",
    "        return df_results\n",
    "    \n",
    "    def _calc_best_score(self, df_results):\n",
    "        val_max_auc = df_results.auc_score.max()\n",
    "        df_max_auc = df_results[df_results.auc_score == val_max_auc]\n",
    "        df_max_auc_index = df_max_auc.index[0]\n",
    "        self.current_thres = df_results.loc[df_max_auc_index, 'current_thres']\n",
    "        self.top_score = val_max_auc \n",
    "    \n",
    "    def _fine_tune_thres(self):\n",
    "        list_tune_thres = []\n",
    "        temp_val_neg = self.current_thres\n",
    "        temp_val_pos = self.current_thres\n",
    "        for val in range(0,5):\n",
    "            temp_val_neg = temp_val_neg - .01\n",
    "            temp_val_pos = temp_val_pos + .01\n",
    "            list_tune_thres.append(round(temp_val_neg, 2))\n",
    "            list_tune_thres.append(round(temp_val_pos, 2))\n",
    "        list_tune_thres.append(round(self.current_thres, 2))    \n",
    "        list_tune_thres.sort()\n",
    "        return list_tune_thres\n",
    "    \n",
    "    def _fine_tune_thres_2(self):\n",
    "        list_tune_thres = []\n",
    "        temp_val_neg = self.current_thres\n",
    "        temp_val_pos = self.current_thres\n",
    "        for val in range(0,5):\n",
    "            temp_val_neg = temp_val_neg - .001\n",
    "            temp_val_pos = temp_val_pos + .001\n",
    "            list_tune_thres.append(round(temp_val_neg, 3))\n",
    "            list_tune_thres.append(round(temp_val_pos, 3))\n",
    "        list_tune_thres.append(round(self.current_thres, 3))    \n",
    "        list_tune_thres.sort()\n",
    "        return list_tune_thres\n",
    "    \n",
    "    def _create_results_df(self):\n",
    "        col_chkpt = pd.Series(sc.chkpt_num, name='chkpt_epoch')\n",
    "        col_thres = pd.Series(self.current_thres, name='best_threshold')\n",
    "        col_auc = pd.Series(self.top_score, name='auc_score')\n",
    "        df_temp = pd.concat([col_chkpt, col_thres, col_auc], axis=1)\n",
    "        print(df_temp)\n",
    "        self.df_all_results = pd.concat([self.df_all_results, df_temp], axis=0)\n",
    "        \n",
    "    def _save_best_thres(self):\n",
    "        dataset = self.df_all_results.copy()\n",
    "        val_best_auc = dataset.auc_score.max()\n",
    "        val_best_chkpt = dataset[dataset.auc_score==val_best_auc].chkpt_epoch\n",
    "        val_best_thres = dataset[dataset.auc_score==val_best_auc].best_threshold\n",
    "        self.best_chkpt = val_best_chkpt[0]\n",
    "        self.best_threshold = val_best_thres[0]\n",
    "\n",
    "\n",
    "# tt = TuneThreshold()\n",
    "# tt.tune_threshold(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "# from sklearn.metrics import roc_curve\n",
    "# from sklearn.metrics import auc\n",
    "\n",
    "class ScoreCheckpoints():\n",
    "    '''Loading and testing each checkpoint\n",
    "    \n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.checkpoint_path = './cp.ckpt/'\n",
    "        self.list_auc_score = []\n",
    "        self.list_epoch = []\n",
    "        self.chkpt_num = []\n",
    "    \n",
    "    def create_chkpt_list(self):\n",
    "        list_checkpoints = []\n",
    "        for file in os.listdir(self.checkpoint_path):\n",
    "            val_checkpoint = file[0:12]\n",
    "            if file[0:3]=='cp-' and val_checkpoint not in list_checkpoints:\n",
    "                list_checkpoints.append(val_checkpoint)\n",
    "        list_checkpoints.sort()\n",
    "        return list_checkpoints\n",
    "    \n",
    "    def score_chkpts(self):\n",
    "        list_checkpoints = self.create_chkpt_list()\n",
    "        list_epoch = []\n",
    "        for chkpt in list_checkpoints[67:68]: # setting 66:67 for fast testing\n",
    "            filepath_chkpt = self.checkpoint_path + chkpt\n",
    "            model = mod.create_model(MODEL_SEQ, METRICS, LR, LOSS)\n",
    "            model.load_weights(filepath_chkpt)\n",
    "            rounded_predictions = model.predict_classes(pp.test_sample, batch_size=10, verbose=0)\n",
    "            auc_score = self._calc_chkpt_score(rounded_predictions)\n",
    "            self.chkpt_num = chkpt[3:7]\n",
    "            tt.tune_threshold(model)\n",
    "            self._plot_auc_scores()\n",
    "        # printing final dataframe results\n",
    "        print(tt.df_all_results)\n",
    "        self._plot_auc_scores()\n",
    "            \n",
    "    def _calc_chkpt_score(self, rounded_predictions):\n",
    "        fpr, tpr, thresholds = roc_curve(pp.test_label, rounded_predictions, pos_label=1)\n",
    "        # cm = confusion_matrix(pp.test_label, rounded_predictions) #not needed for now \n",
    "        auc_score = auc(fpr, tpr)\n",
    "        self.list_auc_score.append(auc_score)\n",
    "        return auc_score\n",
    "    \n",
    "    def _plot_auc_scores(self):\n",
    "        list_epoch = []\n",
    "        for val in range(1, len(self.list_auc_score) + 1):\n",
    "            list_epoch.append(val)\n",
    "        plt.plot(list_epoch, self.list_auc_score)\n",
    "        plt.title(\"Checkpoint Versus AUC Score\")\n",
    "        plt.ylabel(\"AUC Score\")\n",
    "        plt.xlabel(\"Checkpoint / Epoch\")\n",
    "\n",
    "# sc = ScoreCheckpoints()\n",
    "# list_checkpoints = sc.create_chkpt_list()\n",
    "# sc.score_chkpts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from sklearn.preprocessing import binarize\n",
    "# from sklearn.metrics import roc_curve\n",
    "# from sklearn.metrics import auc\n",
    "\n",
    "\n",
    "class SaveModel():\n",
    "    def __init__(self):\n",
    "        self.chkpt_file_path = self._create_file_path()\n",
    "        self.saved_model_file_path = mod.filepath_chkpt + 'saved_model/'\n",
    "    \n",
    "    def _create_file_path(self):\n",
    "        chkpt_file_path = mod.filepath_chkpt + 'cp-' + tt.best_chkpt + '.ckpt'\n",
    "        return chkpt_file_path\n",
    "    \n",
    "    def save_best_model(self):\n",
    "        model = self._load_model_weights()\n",
    "        save_model_file_path = mod.filepath_chkpt + 'saved_model/' #delete this after fixing other bug\n",
    "        tf.saved_model.save(model, self.saved_model_file_path)\n",
    "    \n",
    "    def _load_model_weights(self):\n",
    "        model = mod.create_model(MODEL_SEQ, METRICS, LR, LOSS)\n",
    "        model.load_weights(self.chkpt_file_path)\n",
    "        return model\n",
    "        \n",
    "    def load_saved_model(self, summary=False):\n",
    "        model = tf.keras.models.load_model(self.saved_model_file_path)\n",
    "        if summary:\n",
    "            print('\\n')\n",
    "            print(model.summary())\n",
    "            print('\\n')\n",
    "        return model\n",
    "\n",
    "    def predict_binarize(self, model, test_data):\n",
    "        y_pred = model.predict(pp.test_sample, batch_size=10, verbose=0)\n",
    "        y_pred_class = binarize(y_pred, tt.best_threshold)\n",
    "        fpr, tpr, thresholds = roc_curve(pp.test_label, y_pred_class, pos_label=1)\n",
    "        auc_score = auc(fpr, tpr)\n",
    "        print('\\nauc for best model and best threshold:', auc_score)\n",
    "        return y_pred_class\n",
    "        \n",
    "    \n",
    "# sm = SaveModel()\n",
    "# sm.save_best_model()\n",
    "# model_1 = sm.load_saved_model(summary=True)\n",
    "# y_pred = sm.predict_binarize(model_1, pp.test_sample)\n",
    "# y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (190000, 233)\n",
      "Testing data shape: (47243, 233)\n",
      "Validation data shape: (11811, 233)\n",
      "train_label length: 190000\n",
      "test_label length: 47243\n",
      "val_label length: 11811\n"
     ]
    }
   ],
   "source": [
    "filepath_data = '/Users/krahman/work/tutorials/tensorflow_classification/data/'\n",
    "\n",
    "df_raw = pd.read_csv(filepath_data + 'mod_x_train.csv').drop('Unnamed: 0', axis=1) #del once finished testing\n",
    "\n",
    "train_sample = pd.read_csv(filepath_data + 'mod_x_train.csv').drop('Unnamed: 0', axis=1)\n",
    "train_label = pd.read_csv(filepath_data + 'mod_y_train.csv').drop('Unnamed: 0', axis=1)\n",
    "train_sample = pd.concat([train_sample, train_label], axis=1)\n",
    "test_sample = pd.read_csv(filepath_data + 'mod_x_test.csv').drop('Unnamed: 0', axis=1)\n",
    "test_label = pd.read_csv(filepath_data + 'mod_y_test.csv').drop('index', axis=1)\n",
    "test_sample = pd.concat([test_sample, test_label], axis=1)\n",
    "\n",
    "target = '0'\n",
    "\n",
    "list_data = [train_sample, test_sample]\n",
    "\n",
    "pp = PreProcessing(list_data, target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_model method is set to false.\n"
     ]
    }
   ],
   "source": [
    "mod = CreateModel()\n",
    "###########################\n",
    "##### hard code below #####\n",
    "\n",
    "DF_TRAIN = pp.train_sample\n",
    "\n",
    "##### Defining Model Parameters #####\n",
    "neg, pos = np.bincount(train_sample[target])\n",
    "initial_bias = np.log([pos/neg])\n",
    "OUTPUT_BIAS = tf.keras.initializers.Constant(initial_bias)\n",
    "LOSS = keras.losses.BinaryCrossentropy()\n",
    "LR = .0001\n",
    "METRICS = [keras.metrics.AUC(name='auc'),\n",
    "           keras.metrics.FalsePositives(name='fp'),\n",
    "           keras.metrics.FalseNegatives(name='fn')]\n",
    "\n",
    "MODEL_SEQ = keras.Sequential([keras.layers.Dense(256, activation='relu', kernel_regularizer=l2(0.0001), input_shape=(DF_TRAIN.shape[-1],)),\n",
    "                              keras.layers.Dense(256, activation='relu', kernel_regularizer=l2(0.0001)),\n",
    "                              keras.layers.Dense(256, activation='relu', kernel_regularizer=l2(0.0001)),\n",
    "                              keras.layers.Dense(256, activation='relu', kernel_regularizer=l2(0.0001)),\n",
    "                              keras.layers.Dense(256, activation='relu', kernel_regularizer=l2(0.0001)),\n",
    "                              keras.layers.Dense(256, activation='relu', kernel_regularizer=l2(0.0001)),\n",
    "                              keras.layers.Dense(256, activation='relu', kernel_regularizer=l2(0.0001)),\n",
    "                              keras.layers.Dense(256, activation='relu', kernel_regularizer=l2(0.0001)),\n",
    "                              keras.layers.Dense(256, activation='relu', kernel_regularizer=l2(0.0001)),\n",
    "                              keras.layers.Dropout(.5),\n",
    "                              keras.layers.Dense(1, activation='sigmoid', bias_initializer=OUTPUT_BIAS)])\n",
    "\n",
    "# MODEL_SEQ = keras.Sequential([keras.layers.Dense(16, activation='relu', kernel_regularizer=l2(0.0001), input_shape=(DF_TRAIN.shape[-1],)),\n",
    "#                           keras.layers.Dense(16, activation='relu', kernel_regularizer=l2(0.0001)),\n",
    "#                           keras.layers.Dropout(.5),\n",
    "#                           keras.layers.Dense(1, activation='sigmoid', bias_initializer=OUTPUT_BIAS)])\n",
    "\n",
    "\n",
    "model = mod.create_model(MODEL_SEQ, METRICS, LR, LOSS)\n",
    "mod.fit_model(model, epochs=100, fit_model=False) #comment out until next fitting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = TuneThreshold()\n",
    "# tt.tune_threshold(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  chkpt_epoch  best_threshold  auc_score\n",
      "0        0067           0.168   0.867205\n",
      "  chkpt_epoch  best_threshold  auc_score\n",
      "0        0067           0.168   0.867205\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sc = ScoreCheckpoints()\n",
    "list_checkpoints = sc.create_chkpt_list()\n",
    "sc.score_chkpts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tt.best_chkpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tt = TuneThreshold()\n",
    "# tt.tune_threshold(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sc = ScoreCheckpoints()\n",
    "# list_checkpoints = sc.create_chkpt_list()\n",
    "# sc.score_chkpts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sm.chkpt_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/alpha/guide/checkpoints#loading_mechanics for details.\n",
      "WARNING:tensorflow:From /Users/krahman/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: ./cp.ckpt/saved_model/assets\n",
      "\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 256)               59904     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 586,497\n",
      "Trainable params: 586,497\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "\n",
      "\n",
      "auc for best model and best threshold: 0.8672046757668171\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       ...,\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm = SaveModel()\n",
    "sm.save_best_model()\n",
    "model_1 = sm.load_saved_model(summary=True)\n",
    "y_pred = sm.predict_binarize(model_1, pp.test_sample)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
