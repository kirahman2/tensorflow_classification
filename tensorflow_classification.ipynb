{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import tensorflow as tf\n",
    "# # import random as rn\n",
    "\n",
    "# import keras\n",
    "# from keras import backend as K\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Activation, Dropout\n",
    "# from keras.layers.core import Dense, Flatten\n",
    "from keras.optimizers import Adam\n",
    "# from keras.metrics import categorical_crossentropy\n",
    "# from keras.preprocessing.image import ImageDataGenerator\n",
    "# from keras.layers.normalization import BatchNormalization\n",
    "# from keras.layers.convolutional import *\n",
    "# from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# import itertools\n",
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "\n",
    "# import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "# from sklearn.utils import shuffle\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import os\n",
    "import tempfile\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (377945, 227)\n",
      "Validation data shape: (94487, 227)\n",
      "Testing data shape: (118108, 227)\n"
     ]
    }
   ],
   "source": [
    "filepath_files = '/Users/krahman/work/tutorials/tensorflow_classification/data/'\n",
    "\n",
    "df_features = pd.read_csv(filepath_files + 'df_imputed.csv').drop('Unnamed: 0', axis=1)\n",
    "df_features = shuffle(df_features).reset_index(drop=True)\n",
    "\n",
    "train_samples, test_samples = train_test_split(df_features, test_size=.2)\n",
    "train_samples, val_samples = train_test_split(train_samples, test_size=.2)\n",
    "\n",
    "train_labels = np.array(train_samples.pop('isFraud'))\n",
    "test_labels = np.array(test_samples.pop('isFraud'))\n",
    "val_labels = np.array(val_samples.pop('isFraud'))\n",
    "\n",
    "print(\"Training data shape:\", train_samples.shape)\n",
    "print(\"Validation data shape:\", val_samples.shape)\n",
    "print(\"Testing data shape:\", test_samples.shape)\n",
    "\n",
    "train_samples = np.array(train_samples)\n",
    "test_samples = np.array(test_samples)\n",
    "val_samples = np.array(val_samples)\n",
    "\n",
    "# scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaler = StandardScaler()\n",
    "scaled_train_samples = scaler.fit_transform(train_samples)\n",
    "scaled_test_samples = scaler.transform(test_samples)\n",
    "scaled_val_samples = scaler.transform(val_samples)\n",
    "\n",
    "loss = keras.losses.BinaryCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base model:\n",
      "[[113789    107]\n",
      " [  4194     18]]\n",
      "Train on 377945 samples, validate on 94487 samples\n",
      "Epoch 1/2\n",
      "377945/377945 - 25s - loss: 0.1188 - auc: 0.8175 - fp: 519.0000 - fn: 11385.0000 - val_loss: 0.1116 - val_auc: 0.8434 - val_fp: 111.0000 - val_fn: 2760.0000\n",
      "Epoch 2/2\n",
      "377945/377945 - 21s - loss: 0.1099 - auc: 0.8528 - fp: 624.0000 - fn: 10737.0000 - val_loss: 0.1072 - val_auc: 0.8555 - val_fp: 170.0000 - val_fn: 2599.0000\n",
      "[[113702    194]\n",
      " [  3395    817]]\n"
     ]
    }
   ],
   "source": [
    "# testing softmax\n",
    "neg, pos = np.bincount(df_features.isFraud)\n",
    "initial_bias = np.log([pos/neg])\n",
    "output_bias = tf.keras.initializers.Constant(initial_bias)\n",
    "\n",
    "    \n",
    "# print(output_bias)\n",
    "metrics = [keras.metrics.AUC(name='auc'),\n",
    "           keras.metrics.FalsePositives(name='fp'),\n",
    "           keras.metrics.FalseNegatives(name='fn')]\n",
    "\n",
    "epochs = 2\n",
    "lr = .0001\n",
    "\n",
    "model = keras.Sequential([keras.layers.Dense(64, activation='relu', input_shape=(train_samples.shape[-1],)),\n",
    "                          keras.layers.Dense(64, activation='relu'),\n",
    "#                           keras.layers.Dropout(0.5),\n",
    "                          keras.layers.Dense(1, activation='sigmoid', bias_initializer=output_bias)])\n",
    "\n",
    "# base model predictions\n",
    "predictions = model.predict(scaled_test_samples, batch_size=10, verbose=0)\n",
    "rounded_predictions = model.predict_classes(scaled_test_samples, batch_size=10, verbose=0)\n",
    "cm = confusion_matrix(test_labels, rounded_predictions)\n",
    "print('Base model:')\n",
    "print(cm)\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(lr=lr), loss=loss, metrics=metrics)\n",
    "model.fit(scaled_train_samples, train_labels, validation_data=(scaled_val_samples, val_labels), \n",
    "          batch_size=100, epochs=epochs, shuffle=True, verbose=2, workers=4, \n",
    "          use_multiprocessing=True)\n",
    "\n",
    "predictions = model.predict(scaled_test_samples, batch_size=10, verbose=0)\n",
    "rounded_predictions = model.predict_classes(scaled_test_samples, batch_size=10, verbose=0)\n",
    "cm = confusion_matrix(test_labels, rounded_predictions)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
